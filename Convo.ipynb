{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "# tf.VERSION\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# global varuables\n",
    "w = h = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Reads band images and index images\n",
    "#\n",
    "def read_img(site, _s):\n",
    "    data = []\n",
    "\n",
    "    for i in range(1, 8):\n",
    "        if _s == 'B':\n",
    "            filename = \"input/\"+ site +\"/B\" + str(i) + \"_250_B.tif\"\n",
    "        else:\n",
    "            filename = \"input/\"+ site +\"/B\" + str(i) + \"_250.tif\"\n",
    "            \n",
    "        img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        data.append(img)\n",
    "\n",
    "    index = [\"NDVI.tif\", \"NDWI.tif\", \"NDBI.tif\"]\n",
    "    for i in index:\n",
    "        filename = \"input/\"+ site +\"/\" + i\n",
    "        img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        data.append(img)\n",
    "\n",
    "#     cv2.imshow(\"Image\", data[9])\n",
    "#     cv2.waitKey(0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "i_img = read_img(\"Landsat8-A\", 'A')\n",
    "test_img = read_img(\"Landsat8-B\", 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Region of Interest\n",
    "- extract 9x9 pixels from point(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "def crop_train(_img, _c, site):\n",
    "    _class = \"\"\n",
    "    if(_c == 0):\n",
    "        _class = 'Vegetation'\n",
    "    elif(_c == 1):\n",
    "        _class = 'Built-up'\n",
    "    else:\n",
    "        _class = 'Water'\n",
    "        \n",
    "    _pts = pd.read_excel('input/'+ site +'.xlsx', sheet_name = _class)\n",
    "\n",
    "    # iterate over rows with iterrows()\n",
    "    for index, row in _pts.iterrows():\n",
    "        x = row['X'] - 4\n",
    "        y = row['Y'] - 4\n",
    "        \n",
    "        for img in _img:        \n",
    "            crop_img = img[y:y+h, x:x+w]\n",
    "        \n",
    "    #         if(len(crop_img[5]) < 9):\n",
    "    #         print(row['X'], row['Y'], len(crop_img), len(crop_img[0]), len(crop_img[1]))\n",
    "            X_tr_list.append(crop_img)\n",
    "        y_tr.append(_c)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "def crop_test(_img):\n",
    "    _pts = pd.read_excel('input/site-b.xlsx')\n",
    "\n",
    "    for index, row in _pts.iterrows():\n",
    "        x = row['X'] - 4\n",
    "        y = row['Y'] - 4\n",
    "        \n",
    "        if(row['Class'] == 255):\n",
    "            _c = 0\n",
    "        elif(row['Class'] == 128):\n",
    "            _c = 1\n",
    "        else:\n",
    "            _c = 2\n",
    "        \n",
    "        for img in _img:        \n",
    "            crop_img = img[y:y+h, x:x+w]\n",
    "            X_te_list.append(crop_img)\n",
    "        y_te.append(_c)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "2000\n",
      "200\n",
      "Testing...\n",
      "2000\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# TRAINING SET SITE A ------------------------------------------------------------------\n",
    "X_tr_list = []\n",
    "y_tr = []\n",
    "\n",
    "crop_train(i_img, 0, 'site-a')\n",
    "crop_train(i_img, 1, 'site-a')\n",
    "crop_train(i_img, 2, 'site-a')\n",
    "\n",
    "print(\"Training...\")\n",
    "print(len(X_tr_list))\n",
    "print(len(y_tr))\n",
    "\n",
    "# TRAINING SET SITE B ------------------------------------------------------------------\n",
    "X_te_list = []\n",
    "y_te = []\n",
    "\n",
    "crop_test(i_img)\n",
    "print(\"Testing...\")\n",
    "print(len(X_te_list))\n",
    "print(len(y_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Training and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9, 9)\n",
      "[[74 84 68 66 72 67 68 72 80]\n",
      " [70 66 66 60 89 64 59 70 66]\n",
      " [91 57 62 55 70 62 60 70 68]\n",
      " [72 76 61 53 62 53 62 70 65]\n",
      " [61 57 62 56 51 50 59 66 66]\n",
      " [76 62 62 62 51 53 66 66 70]\n",
      " [68 66 56 50 56 50 51 64 68]\n",
      " [70 64 56 56 58 51 49 54 60]\n",
      " [68 70 56 50 54 54 54 56 68]] 0\n",
      "(10, 9, 9)\n",
      "[[ 80  72  89 113 107 107  88  84  76]\n",
      " [ 78  80  93  99  90  92  76  78  80]\n",
      " [ 80  82  83  78  92  90  74  76  74]\n",
      " [ 95  87  82  76  87  91  88  85  70]\n",
      " [ 92 103  80  70  74  80 106  74  63]\n",
      " [ 96 105 109  74  70 104  90  70  68]\n",
      " [ 82  80  97  96  72 101  76  70  76]\n",
      " [ 95 110  90  97  86  88  66  64  62]\n",
      " [100 103 110  97 101  87  88  76  68]] 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_tr = []\n",
    "X_tr = np.array(X_tr_list).reshape(-1, 10, 9, 9)\n",
    "\n",
    "print(X_tr[0].shape)\n",
    "print(X_tr[0, 9], y_tr[0])\n",
    "\n",
    "\n",
    "X_te = []\n",
    "X_te = np.array(X_te_list).reshape(-1, 10, 9, 9)\n",
    "\n",
    "print(X_te[0].shape)\n",
    "print(X_te[0, 9], y_te[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Neural Network: Basic CLassification\n",
    "- https://www.tensorflow.org/tutorials/keras/basic_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Layers, Compile Model, and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abe-r\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 0s 538us/sample - loss: 1.2517 - acc: 0.5750\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s 65us/sample - loss: 1.0940 - acc: 0.5950\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 0s 50us/sample - loss: 1.0909 - acc: 0.5950\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 0s 65us/sample - loss: 1.0877 - acc: 0.5950\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 0s 50us/sample - loss: 1.0845 - acc: 0.5950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d8feccbcf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup\n",
    "model_1 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = X_tr.shape[1:]),\n",
    "    keras.layers.Dense(1, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model_1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train\n",
    "model_1.fit(X_tr, y_tr, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 300us/sample - loss: 1.0891 - acc: 0.4050\n",
      "Test accuracy: 0.405\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_1.evaluate(X_te, y_te)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33192247, 0.3449448 , 0.32313272], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_1.predict(X_te)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Conv2D(32, (1, 1), activation='relu', input_shape=X_tr.shape[1:]))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Conv2D(64, (1, 1), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 10, 9, 32)         320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 5, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 64)          4160      \n",
      "=================================================================\n",
      "Total params: 22,976\n",
      "Trainable params: 22,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(layers.Flatten())\n",
    "model_2.add(layers.Dense(1, activation='relu'))\n",
    "model_2.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 10, 9, 32)         320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 5, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 64)          4160      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 6         \n",
      "=================================================================\n",
      "Total params: 23,047\n",
      "Trainable params: 23,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 2.1828 - acc: 0.4950\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 1.0946 - acc: 0.5950\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 0s 160us/sample - loss: 1.0916 - acc: 0.5950\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 0s 160us/sample - loss: 1.0887 - acc: 0.5950\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 0s 165us/sample - loss: 1.0856 - acc: 0.5950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d88070e4e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(X_tr, y_tr, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 314us/sample - loss: 1.0894 - acc: 0.4050\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_2.evaluate(X_te, y_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
